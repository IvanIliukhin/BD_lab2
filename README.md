# Анализ литературного произведения с использованием Apache Spark

Анализ романа А.И. Герцена «Кто виноват?» с помощью Apache Spark RDD в standalone-режиме.

## Описание

Проект выполняет полный анализ текста:
- Очистка и предобработка текста
- Подсчёт частоты слов (WordCount)
- Выявление ТОП-50 самых частых и редких слов
- Стемминг русских слов
- Сравнительный анализ до и после стемминга

## Технологии

- Python 3.x
- Apache Spark (PySpark)
- NLTK (стоп-слова, стемминг)
- chardet (определение кодировки)

## Установка и запуск

1. Установите зависимости:
```bash
pip install pyspark nltk chardet
```
2. Поместите файл kto_vinovat.txt в корневую директорию

3. Запустить:

```bash
python analyze_the_literary_work.py
```
# Результат
- Обработано 42 137 слов

- Определены ключевые темы и персонажи

- Количество уникальных слов сократилось на 39% после удаления корня

- Проведен анализ наиболее часто встречающихся слов
